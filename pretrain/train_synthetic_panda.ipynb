{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "base_dir = os.path.abspath(\"../\")\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import kornia\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from imageloaders.DREAM import ImageDataLoaderSynthetic\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.n_kp = 12\n",
    "args.scale = 0.5\n",
    "args.height = 480\n",
    "args.width = 640\n",
    "args.fx = -320.\n",
    "args.fy = -320.\n",
    "args.px = 320.\n",
    "args.py = 240.\n",
    "args.lim=[-1., 1., -1., 1.]\n",
    "args.base_dir = '/home/jingpei/Desktop/CtRNet-robot-pose-estimation'\n",
    "#args.test_data_folder = '/media/jingpei/DATA/DREAM/data/synthetic/panda_synth_test_dr'\n",
    "args.data_folder = '/media/jingpei/DATA/DREAM/data/synthetic/panda_synth_test_photo'\n",
    "args.test_data_folder = args.data_folder\n",
    "args.use_gpu = True\n",
    "args.batch_size = 32\n",
    "args.num_workers = 8\n",
    "args.lr = 1e-5\n",
    "args.beta1 = 0.9\n",
    "args.n_epoch = 1000\n",
    "args.out_dir = 'outputs'\n",
    "args.ckp_per_epoch = 10\n",
    "\n",
    "\n",
    "args.height = int(args.height * args.scale)\n",
    "args.width = int(args.width * args.scale)\n",
    "args.fx = args.fx * args.scale\n",
    "args.fy = args.fy * args.scale\n",
    "args.px = args.px * args.scale\n",
    "args.py = args.py * args.scale\n",
    "\n",
    "if not os.path.exists(args.out_dir):\n",
    "    os.mkdir(args.out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "data_n_batches = {}\n",
    "for phase in ['train','valid']:\n",
    "    datasets[phase] = ImageDataLoaderSynthetic(data_folder = args.data_folder if phase=='train' else args.test_data_folder, scale = args.scale, trans_to_tensor = trans_to_tensor)\n",
    "\n",
    "\n",
    "    dataloaders[phase] = DataLoader(\n",
    "        datasets[phase], batch_size=args.batch_size,\n",
    "        shuffle=True if phase == 'train' else False,\n",
    "        num_workers=args.num_workers)\n",
    "\n",
    "    data_n_batches[phase] = len(dataloaders[phase])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import models.BPnP as BPnP\n",
    "import kornia as kn\n",
    "\n",
    "from models.keypoint_seg_resnet import KeyPointSegNet\n",
    "\n",
    "keypoint_seg_predictor = KeyPointSegNet(args, use_gpu=args.use_gpu)\n",
    "if args.use_gpu:\n",
    "    keypoint_seg_predictor = keypoint_seg_predictor.cuda()\n",
    "\n",
    "#keypoint_seg_predictor = torch.nn.DataParallel(keypoint_seg_predictor, device_ids=[0])\n",
    "bpnp = BPnP.BPnP.apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heatmap import GaussianHeatmapLoss, heatmap_to_keypoints\n",
    "heatmapLoss = GaussianHeatmapLoss()\n",
    "criterionBCE = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(keypoint_seg_predictor.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if args.use_gpu:\n",
    "    heatmapLoss = heatmapLoss.cuda()\n",
    "    criterionBCE = criterionBCE.cuda()\n",
    "\n",
    "if args.use_gpu:\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    \n",
    "\n",
    "fx = args.fx\n",
    "fy = args.fy\n",
    "px = args.px\n",
    "py = args.py\n",
    "intrinsics = np.array([[  fx        ,    0.   ,  px        ],\n",
    "                       [  0.        ,    fy   ,  py        ],\n",
    "                       [  0.        ,    0.   ,   1.      ]])\n",
    "\n",
    "K = torch.tensor(intrinsics, device=device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.robot_arm import PandaArm\n",
    "from models.mesh_renderer import RobotMeshRenderer\n",
    "\n",
    "urdf_file = os.path.join(args.base_dir,\"urdfs/Panda/panda.urdf\")\n",
    "panda_arm = PandaArm(urdf_file=urdf_file)\n",
    "\n",
    "\n",
    "focal_length = [-args.fx,-args.fy]\n",
    "principal_point = [args.px, args.py]\n",
    "image_size = [args.height,args.width]\n",
    "mesh_files = [args.base_dir + \"/urdfs/Panda/meshes/visual/link0/link0.obj\",\n",
    "              args.base_dir + \"/urdfs/Panda/meshes/visual/link1/link1.obj\",\n",
    "              args.base_dir + \"/urdfs/Panda/meshes/visual/link2/link2.obj\",\n",
    "              args.base_dir + \"/urdfs/Panda/meshes/visual/link3/link3.obj\",\n",
    "              args.base_dir + \"/urdfs/Panda/meshes/visual/link4/link4.obj\",\n",
    "              args.base_dir + \"/urdfs/Panda/meshes/visual/link5/link5.obj\",\n",
    "              args.base_dir + \"/urdfs/Panda/meshes/visual/link6/link6.obj\",\n",
    "              args.base_dir + \"/urdfs/Panda/meshes/visual/link7/link7.obj\",\n",
    "              args.base_dir + \"/urdfs/Panda/meshes/visual/hand/hand.obj\",\n",
    "             ]\n",
    "\n",
    "            \n",
    "panda_renderer = RobotMeshRenderer(\n",
    "    focal_length=focal_length, principal_point=principal_point, image_size=image_size, \n",
    "    robot=panda_arm, mesh_files=mesh_files, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ab8dc3c7a449fd8dc8858f276e0869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jingpei/anaconda3/envs/pytorch_ros/lib/python3.8/site-packages/pytorch3d/transforms/transform3d.py:800: UserWarning: R is not a valid rotation matrix\n",
      "  warnings.warn(msg)\n",
      "/home/jingpei/anaconda3/envs/pytorch_ros/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate tuple (not \"Tensor\") to tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10619/1781125890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mloss_heatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheatmapLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_2d_gt_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_heatmap\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_seg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mmeter_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate tuple (not \"Tensor\") to tuple"
     ]
    }
   ],
   "source": [
    "st_epoch = 0\n",
    "epoch_writer = SummaryWriter(comment=\"_writter\")\n",
    "\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(0, args.n_epoch):\n",
    "    phases = ['train','valid']\n",
    "\n",
    "    for phase in phases:\n",
    "        iter_writer = SummaryWriter(comment=\"_epoch_\" + str(epoch) + \"_\" + phase)\n",
    "\n",
    "        # train keypoint detector\n",
    "        \n",
    "        keypoint_seg_predictor.train(phase == 'train')\n",
    "\n",
    "        meter_loss = AverageMeter()\n",
    "        meter_loss_kp = AverageMeter()\n",
    "        meter_loss_seg = AverageMeter()\n",
    "\n",
    "\n",
    "        loader = dataloaders[phase]\n",
    "\n",
    "        #bar = ProgressBar(maxval=data_n_batches[phase])\n",
    "        for i, data in tqdm(enumerate(loader), total=data_n_batches[phase]):\n",
    "\n",
    "            if args.use_gpu:\n",
    "                if isinstance(data, list):\n",
    "                    data = [d.cuda() for d in data]\n",
    "                else:\n",
    "                    data = data.cuda()\n",
    "\n",
    "            # load data\n",
    "            img, joint_angle, base_to_cam = data\n",
    "\n",
    "            # generate ground truth\n",
    "            mask_list_gt = list()\n",
    "            points_2d_gt_list = list()\n",
    "            for b in range(img.shape[0]):\n",
    "                robot_mesh = panda_renderer.get_robot_mesh(joint_angle[b].cpu().squeeze())\n",
    "                rendered_image = panda_renderer.silhouette_renderer(meshes_world=robot_mesh, R = base_to_cam[b,:3,:3].T.unsqueeze(0), T = base_to_cam[b,:3,3].unsqueeze(0))\n",
    "                mask_list_gt.append(rendered_image[..., 3])\n",
    "\n",
    "                points = panda_arm.get_3d_keypoints(joint_angle[b].cpu().squeeze())\n",
    "                points_3d = torch.from_numpy(points).float().to(device)\n",
    "                points_2d_gt = BPnP.batch_project(base_to_cam[b,:3,:4][None], points_3d, K, angle_axis=False)\n",
    "                points_2d_gt_list.append(points_2d_gt)\n",
    "                # debug\n",
    "                #if (points_2d_gt[0,:,0] > args.width).any():\n",
    "                #    print(points_2d_gt[0,(points_2d_gt[0,:,0] > args.width)])\n",
    "                #if (points_2d_gt[0,:,1] > args.height).any():\n",
    "                #    print(points_2d_gt[0,(points_2d_gt[0,:,1] > args.height)])\n",
    "\n",
    "            mask_batch = torch.cat(mask_list_gt,0)\n",
    "            points_2d_gt_batch = torch.cat(points_2d_gt_list,0)\n",
    "            valid_point_table = torch.logical_and(torch.logical_and(points_2d_gt_batch[:,:,0] < args.width, points_2d_gt_batch[:,:,0] > 0), \n",
    "                                      torch.logical_and(points_2d_gt_batch[:,:,1] < args.height, points_2d_gt_batch[:,:,1] > 0))\n",
    "\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "\n",
    "                # detect 2d keypoints\n",
    "                heatmap, segmentation = keypoint_seg_predictor(img)\n",
    "\n",
    "                loss_seg = criterionBCE(segmentation.squeeze(), mask_batch)\n",
    "                loss_heatmap,_ = heatmapLoss(heatmap, points_2d_gt_batch)\n",
    "\n",
    "                loss = loss_heatmap + loss_seg\n",
    "\n",
    "                meter_loss.update(loss.item(), n=img.size(0))\n",
    "                meter_loss_kp.update(loss_heatmap.item(), n=img.size(0))\n",
    "                meter_loss_seg.update(loss_seg.item(), n=img.size(0))\n",
    "\n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_value_(keypoint_seg_predictor.parameters(), 10)\n",
    "                optimizer.step()\n",
    "\n",
    "            # write to log\n",
    "\n",
    "            iter_writer.add_scalar('loss_kp', loss_heatmap.item(), i)\n",
    "            iter_writer.add_scalar('loss_seg', loss_seg.item(), i)\n",
    "            iter_writer.add_scalar('loss_all', loss.item(), i)\n",
    "\n",
    "            if (i%200==0 and phase=='train') or (phase=='valid' and i%20==0):\n",
    "\n",
    "                points_2d = heatmap_to_keypoints(heatmap)\n",
    "                img_np = to_numpy_img(img[0])\n",
    "                img_np_pred = overwrite_image(img_np.copy(),points_2d[0].detach().cpu().numpy().squeeze().astype(int), color=(0,1,0),point_size=6)\n",
    "                img_np_gt = overwrite_image(img_np.copy(),points_2d_gt_batch[0].detach().cpu().numpy().squeeze().astype(int), color=(0,1,0),point_size=6)\n",
    "                iter_writer.add_image('[keypoint] gt vs predict', np.concatenate((img_np_gt,img_np_pred),axis=1), i, dataformats='HWC')\n",
    "\n",
    "                iter_writer.add_image('[segmentation] gt vs predict', np.concatenate((mask_batch[0].squeeze().cpu().detach().numpy(),\n",
    "                                                                        torch.sigmoid(segmentation[0]).squeeze().cpu().detach().numpy()),\n",
    "                                                                        axis=1), i, dataformats='HW')\n",
    "\n",
    "        log = '%s [%d/%d] Loss: %.6f, LR: %f' % (\n",
    "            phase, epoch, args.n_epoch,\n",
    "            meter_loss.avg,\n",
    "            get_lr(optimizer))\n",
    "\n",
    "        iter_writer.close()\n",
    "\n",
    "        print(log)\n",
    "\n",
    "        if phase == 'valid':\n",
    "            epoch_writer.add_scalar('loss_kp_val', meter_loss_kp.avg, epoch)\n",
    "            epoch_writer.add_scalar('loss_seg_val', meter_loss_seg.avg, epoch)\n",
    "            epoch_writer.add_scalar('loss_all_val', meter_loss.avg, epoch)\n",
    "\n",
    "            scheduler.step(meter_loss.avg)\n",
    "            if meter_loss.avg < best_valid_loss:\n",
    "                best_valid_loss = meter_loss.avg\n",
    "\n",
    "                torch.save(keypoint_seg_predictor.state_dict(), '%s/net_best.pth' % (args.out_dir))\n",
    "\n",
    "            log = 'Best valid: %.6f' % (best_valid_loss)\n",
    "            print(log)\n",
    "            torch.save(keypoint_seg_predictor.state_dict(), '%s/net_last.pth' % (args.out_dir))\n",
    "        else:\n",
    "            epoch_writer.add_scalar('loss_kp', meter_loss_kp.avg, epoch)\n",
    "            epoch_writer.add_scalar('loss_seg', meter_loss_seg.avg, epoch)\n",
    "            epoch_writer.add_scalar('loss_all', meter_loss.avg, epoch)\n",
    "            \n",
    "epoch_writer.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d6a47811f83877b7bbb745dc81bd745068b9357c68b4172653992464c04daed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
