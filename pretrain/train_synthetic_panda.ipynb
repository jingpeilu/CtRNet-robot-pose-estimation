{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "base_dir = os.path.abspath(\"../\")\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import kornia\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from imageloaders.DREAM import ImageDataLoaderSynthetic, LabelGenerator\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from utils import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.n_kp = 12\n",
    "args.scale = 0.5\n",
    "args.height = 480\n",
    "args.width = 640\n",
    "args.fx = -320.\n",
    "args.fy = -320.\n",
    "args.px = 320.\n",
    "args.py = 240.\n",
    "args.lim=[-1., 1., -1., 1.]\n",
    "args.base_dir = '/home/jingpei/Desktop/CtRNet-robot-pose-estimation'\n",
    "#args.test_data_folder = '/media/jingpei/DATA/DREAM/data/synthetic/panda_synth_test_dr'\n",
    "args.data_folder = '/media/jingpei/DATA/DREAM/data/synthetic/panda_synth_test_photo'\n",
    "args.test_data_folder = args.data_folder\n",
    "args.use_gpu = True\n",
    "args.batch_size = 32\n",
    "args.num_workers = 8\n",
    "args.lr = 1e-5\n",
    "args.beta1 = 0.9\n",
    "args.n_epoch = 1000\n",
    "args.out_dir = 'outputs'\n",
    "args.ckp_per_epoch = 10\n",
    "\n",
    "\n",
    "args.height = int(args.height * args.scale)\n",
    "args.width = int(args.width * args.scale)\n",
    "args.fx = args.fx * args.scale\n",
    "args.fy = args.fy * args.scale\n",
    "args.px = args.px * args.scale\n",
    "args.py = args.py * args.scale\n",
    "\n",
    "if not os.path.exists(args.out_dir):\n",
    "    os.mkdir(args.out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "datasets = {}\n",
    "dataloaders = {}\n",
    "data_n_batches = {}\n",
    "for phase in ['train','valid']:\n",
    "    datasets[phase] = ImageDataLoaderSynthetic(data_folder = args.data_folder if phase=='train' else args.test_data_folder, scale = args.scale, trans_to_tensor = trans_to_tensor)\n",
    "\n",
    "\n",
    "    dataloaders[phase] = DataLoader(\n",
    "        datasets[phase], batch_size=args.batch_size,\n",
    "        shuffle=True if phase == 'train' else False,\n",
    "        num_workers=args.num_workers)\n",
    "\n",
    "    data_n_batches[phase] = len(dataloaders[phase])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ground-truth masks and keypoints for /media/jingpei/DATA/DREAM/data/synthetic/panda_synth_test_photo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af05c85edd76483993a42e4dd2a33376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ground-truth masks and keypoints for /media/jingpei/DATA/DREAM/data/synthetic/panda_synth_test_photo\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451a65f58c65456694e5027870767b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelgenerator = LabelGenerator(args, args.data_folder)\n",
    "print(\"Generating ground-truth masks and keypoints for {}\".format(args.data_folder))\n",
    "for i in tqdm(range(len(labelgenerator.ndds_dataset))):\n",
    "    labelgenerator.generate_mask(i)\n",
    "    labelgenerator.generate_keypoints(i)\n",
    "\n",
    "print(\"Generating ground-truth masks and keypoints for {}\".format(args.test_data_folder))\n",
    "labelgenerator = LabelGenerator(args, args.test_data_folder)\n",
    "for i in tqdm(range(len(labelgenerator.ndds_dataset))):\n",
    "    labelgenerator.generate_mask(i)\n",
    "    labelgenerator.generate_keypoints(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kornia as kn\n",
    "\n",
    "from models.keypoint_seg_resnet import KeyPointSegNet\n",
    "\n",
    "keypoint_seg_predictor = KeyPointSegNet(args, use_gpu=args.use_gpu)\n",
    "if args.use_gpu:\n",
    "    keypoint_seg_predictor = keypoint_seg_predictor.cuda()\n",
    "\n",
    "#keypoint_seg_predictor = torch.nn.DataParallel(keypoint_seg_predictor, device_ids=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.heatmap import GaussianHeatmapLoss, heatmap_to_keypoints\n",
    "heatmapLoss = GaussianHeatmapLoss()\n",
    "criterionBCE = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(keypoint_seg_predictor.parameters(), lr=args.lr, betas=(args.beta1, 0.999))\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if args.use_gpu:\n",
    "    heatmapLoss = heatmapLoss.cuda()\n",
    "    criterionBCE = criterionBCE.cuda()\n",
    "\n",
    "if args.use_gpu:\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427fc581d70742e2aeba2370fbf771d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jingpei/anaconda3/envs/pytorch_ros/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272068694/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [0/1000] Loss: 0.485659, LR: 0.000010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2684252ed6474e718bf928d5bfd0f83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid [0/1000] Loss: 0.319086, LR: 0.000010\n",
      "Best valid: 0.319086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dcf1becbe14936b2648311007ffc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [1/1000] Loss: 0.298333, LR: 0.000010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f9c4b74ca04e2f822980249adee05b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid [1/1000] Loss: 0.254388, LR: 0.000010\n",
      "Best valid: 0.254388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f8d943734f4c109985e7c68136d41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [2/1000] Loss: 0.249210, LR: 0.000010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a006d61327446f9fd2d188c5841663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid [2/1000] Loss: 0.221737, LR: 0.000010\n",
      "Best valid: 0.221737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19529079075d4751a07f90bb15eb7618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [3/1000] Loss: 0.222101, LR: 0.000010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1156f1f044ea4811a6a1e168c700163f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid [3/1000] Loss: 0.207791, LR: 0.000010\n",
      "Best valid: 0.207791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9201b38aa104b7f8ce882fd5083c08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31177/854285353.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_value_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeypoint_seg_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# write to log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ros/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ros/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ros/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    134\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_ros/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "st_epoch = 0\n",
    "epoch_writer = SummaryWriter(comment=\"_writter\")\n",
    "\n",
    "best_valid_loss = np.inf\n",
    "\n",
    "for epoch in range(0, args.n_epoch):\n",
    "    phases = ['train','valid']\n",
    "\n",
    "    for phase in phases:\n",
    "        iter_writer = SummaryWriter(comment=\"_epoch_\" + str(epoch) + \"_\" + phase)\n",
    "\n",
    "        # train keypoint detector\n",
    "        \n",
    "        keypoint_seg_predictor.train(phase == 'train')\n",
    "\n",
    "        meter_loss = AverageMeter()\n",
    "        meter_loss_kp = AverageMeter()\n",
    "        meter_loss_seg = AverageMeter()\n",
    "\n",
    "\n",
    "        loader = dataloaders[phase]\n",
    "\n",
    "        #bar = ProgressBar(maxval=data_n_batches[phase])\n",
    "        for i, data in tqdm(enumerate(loader), total=data_n_batches[phase]):\n",
    "\n",
    "            if args.use_gpu:\n",
    "                if isinstance(data, list):\n",
    "                    data = [d.cuda() for d in data]\n",
    "                else:\n",
    "                    data = data.cuda()\n",
    "\n",
    "            # load data\n",
    "            img, _, _, points_2d_gt_batch, mask_batch = data\n",
    "\n",
    "            valid_point_table = torch.logical_and(torch.logical_and(points_2d_gt_batch[:,:,0] < args.width, points_2d_gt_batch[:,:,0] > 0), \n",
    "                                      torch.logical_and(points_2d_gt_batch[:,:,1] < args.height, points_2d_gt_batch[:,:,1] > 0))\n",
    "\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "\n",
    "                # detect 2d keypoints\n",
    "                heatmap, segmentation = keypoint_seg_predictor(img)\n",
    "\n",
    "                loss_seg = criterionBCE(segmentation.squeeze(), mask_batch)\n",
    "                loss_heatmap,_ = heatmapLoss(heatmap, points_2d_gt_batch)\n",
    "\n",
    "                loss = loss_heatmap + loss_seg\n",
    "\n",
    "                meter_loss.update(loss.item(), n=img.size(0))\n",
    "                meter_loss_kp.update(loss_heatmap.item(), n=img.size(0))\n",
    "                meter_loss_seg.update(loss_seg.item(), n=img.size(0))\n",
    "\n",
    "            if phase == 'train':\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_value_(keypoint_seg_predictor.parameters(), 10)\n",
    "                optimizer.step()\n",
    "\n",
    "            # write to log\n",
    "\n",
    "            iter_writer.add_scalar('loss_kp', loss_heatmap.item(), i)\n",
    "            iter_writer.add_scalar('loss_seg', loss_seg.item(), i)\n",
    "            iter_writer.add_scalar('loss_all', loss.item(), i)\n",
    "\n",
    "            if (i%200==0 and phase=='train') or (phase=='valid' and i%20==0):\n",
    "\n",
    "                points_2d = heatmap_to_keypoints(heatmap)\n",
    "                img_np = to_numpy_img(img[0])\n",
    "                img_np_pred = overwrite_image(img_np.copy(),points_2d[0].detach().cpu().numpy().squeeze().astype(int), color=(0,1,0),point_size=6)\n",
    "                img_np_gt = overwrite_image(img_np.copy(),points_2d_gt_batch[0].detach().cpu().numpy().squeeze().astype(int), color=(0,1,0),point_size=6)\n",
    "                iter_writer.add_image('[keypoint] gt vs predict', np.concatenate((img_np_gt,img_np_pred),axis=1), i, dataformats='HWC')\n",
    "\n",
    "                iter_writer.add_image('[segmentation] gt vs predict', np.concatenate((mask_batch[0].squeeze().cpu().detach().numpy(),\n",
    "                                                                        torch.sigmoid(segmentation[0]).squeeze().cpu().detach().numpy()),\n",
    "                                                                        axis=1), i, dataformats='HW')\n",
    "\n",
    "        log = '%s [%d/%d] Loss: %.6f, LR: %f' % (\n",
    "            phase, epoch, args.n_epoch,\n",
    "            meter_loss.avg,\n",
    "            get_lr(optimizer))\n",
    "\n",
    "        iter_writer.close()\n",
    "\n",
    "        print(log)\n",
    "\n",
    "        if phase == 'valid':\n",
    "            epoch_writer.add_scalar('loss_kp_val', meter_loss_kp.avg, epoch)\n",
    "            epoch_writer.add_scalar('loss_seg_val', meter_loss_seg.avg, epoch)\n",
    "            epoch_writer.add_scalar('loss_all_val', meter_loss.avg, epoch)\n",
    "\n",
    "            scheduler.step(meter_loss.avg)\n",
    "            if meter_loss.avg < best_valid_loss:\n",
    "                best_valid_loss = meter_loss.avg\n",
    "\n",
    "                torch.save(keypoint_seg_predictor.state_dict(), '%s/net_best.pth' % (args.out_dir))\n",
    "\n",
    "            log = 'Best valid: %.6f' % (best_valid_loss)\n",
    "            print(log)\n",
    "            #torch.save(keypoint_seg_predictor.state_dict(), '%s/net_last.pth' % (args.out_dir))\n",
    "            if epoch % args.ckp_per_epoch == 0:\n",
    "                torch.save(keypoint_seg_predictor.state_dict(), '%s/net_%d.pth' % (args.out_dir, epoch))\n",
    "        else:\n",
    "            epoch_writer.add_scalar('loss_kp', meter_loss_kp.avg, epoch)\n",
    "            epoch_writer.add_scalar('loss_seg', meter_loss_seg.avg, epoch)\n",
    "            epoch_writer.add_scalar('loss_all', meter_loss.avg, epoch)\n",
    "            \n",
    "epoch_writer.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d6a47811f83877b7bbb745dc81bd745068b9357c68b4172653992464c04daed"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
