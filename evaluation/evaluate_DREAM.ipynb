{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "base_dir = \"/home/jingpei/Desktop/CtRNet-robot-pose-estimation\"\n",
    "sys.path.append(base_dir)\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from models.CtRNet import CtRNet\n",
    "from models.BPnP import batch_transform_3d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from imageloaders.DREAM import ImageDataLoaderReal, load_camera_parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.data_folder = \"/media/jingpei/DATA/DREAM/data/real/panda-3cam_realsense\"\n",
    "args.base_dir = \"/home/jingpei/Desktop/CtRNet-robot-pose-estimation\"\n",
    "args.use_gpu = True\n",
    "args.trained_on_multi_gpus = True\n",
    "args.keypoint_seg_model_path = os.path.join(args.base_dir,\"weights/panda/panda-3cam_realsense/net.pth\")\n",
    "args.urdf_file = os.path.join(args.base_dir,\"urdfs/Panda/panda.urdf\")\n",
    "\n",
    "args.robot_name = 'Panda' # \"Panda\" or \"Baxter_left_arm\"\n",
    "args.n_kp = 7\n",
    "args.scale = 0.5\n",
    "args.height = 480\n",
    "args.width = 640\n",
    "args.fx, args.fy, args.px, args.py = load_camera_parameters(args.data_folder)\n",
    "\n",
    "# scale the camera parameters\n",
    "args.width = int(args.width * args.scale)\n",
    "args.height = int(args.height * args.scale)\n",
    "args.fx = args.fx * args.scale\n",
    "args.fy = args.fy * args.scale\n",
    "args.px = args.px * args.scale\n",
    "args.py = args.py * args.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading keypoint segmentation model from /home/jingpei/Desktop/CtRNet-robot-pose-estimation/weights/panda/panda-3cam_realsense/net.pth\n",
      "Camera intrinsics: [[307.76196289   0.         164.13032532]\n",
      " [  0.         307.60958862 125.89585114]\n",
      " [  0.           0.           1.        ]]\n",
      "Robot model: Panda\n"
     ]
    }
   ],
   "source": [
    "CtRNet = CtRNet(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dataset = ImageDataLoaderReal(data_folder = args.data_folder, scale = args.scale, trans_to_tensor = trans_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de685e4b97242bfa46d52994ff1ef06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "err_3d_list = list()\n",
    "err_2d_list = list()\n",
    "\n",
    "for data_n in tqdm(range(len(dataset))):\n",
    "    img, joint_angles, keypoints = dataset.get_data_with_keypoints(data_n) \n",
    "\n",
    "    if args.use_gpu:\n",
    "    \n",
    "        img = img.cuda()\n",
    "\n",
    "    cTr, points_2d, segmentation = CtRNet.inference_single_image(img, joint_angles.cpu().squeeze())\n",
    "\n",
    "    # get ground truth\n",
    "    points_2d_gt = list()\n",
    "    points_3d_gt = list()\n",
    "    for i in range(len(keypoints)):\n",
    "        points_2d_gt.append(keypoints[i]['projected_location'])\n",
    "        points_3d_gt.append(keypoints[i]['location'])\n",
    "\n",
    "    points_2d_gt = np.array(points_2d_gt)\n",
    "    points_3d_gt = np.array(points_3d_gt)\n",
    "\n",
    "\n",
    "    # compute 3d keypoints\n",
    "    _,t_list = CtRNet.robot.get_joint_RT(joint_angles.cpu().squeeze())\n",
    "    points_3d = torch.from_numpy(t_list).float().cuda()\n",
    "\n",
    "    points_3d_pred = to_np(batch_transform_3d(cTr, points_3d)).squeeze()\n",
    "    points_3d_pred = points_3d_pred[[0,2,3,4,6,7,8]]\n",
    "\n",
    "\n",
    "    if points_3d_pred[0,-1] < 0:\n",
    "        points_3d_pred = -points_3d_pred\n",
    "\n",
    "    err_3d = np.linalg.norm(points_3d_pred - points_3d_gt,axis=1)\n",
    "    err_3d = np.mean(err_3d)\n",
    "    err_3d_list.append(err_3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_3d_list = np.array(err_3d_list).flatten()\n",
    "err_3d_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9079485195154777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADD = list()\n",
    "for i in range(1000):\n",
    "    num = np.sum(err_3d_list < i/10000.0) / err_3d_list.shape[0]\n",
    "    ADD.append(num)\n",
    "\n",
    "np.sum(ADD)/len(ADD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0095501947591769"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(err_3d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_ros",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
