{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from ros_nodes.particle_filter import *\n",
    "from ros_nodes.probability_funcs import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage\n",
    "import cv2\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from models.CtRNet import CtRNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.base_dir = \"/home/workspace/src/ctrnet-robot-pose-estimation-ros\"\n",
    "args.use_gpu = True\n",
    "args.trained_on_multi_gpus = True\n",
    "args.keypoint_seg_model_path = os.path.join(args.base_dir,\"weights/panda/panda-3cam_azure/net.pth\")\n",
    "args.urdf_file = os.path.join(args.base_dir,\"urdfs/Panda/panda.urdf\")\n",
    "\n",
    "args.robot_name = 'Panda' # \"Panda\" or \"Baxter_left_arm\"\n",
    "args.n_kp = 7\n",
    "args.height = 480\n",
    "args.width = 640\n",
    "args.fx, args.fy, args.px, args.py = 399.6578776041667, 399.4959309895833, 319.8955891927083, 244.0602823893229\n",
    "args.scale = 0.5 # scale the input image size to (320,240)\n",
    "\n",
    "# scale the camera parameters\n",
    "args.width = int(args.width * args.scale)\n",
    "args.height = int(args.height * args.scale)\n",
    "args.fx = args.fx * args.scale\n",
    "args.fy = args.fy * args.scale\n",
    "args.px = args.px * args.scale\n",
    "args.py = args.py * args.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading keypoint segmentation model from /home/workspace/src/ctrnet-robot-pose-estimation-ros/weights/panda/panda-3cam_azure/net.pth\n",
      "Camera intrinsics: [[199.8289388    0.         159.9477946 ]\n",
      " [  0.         199.74796549 122.03014119]\n",
      " [  0.           0.           1.        ]]\n",
      "Robot model: Panda\n"
     ]
    }
   ],
   "source": [
    "trans_to_tensor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def preprocess_img(cv_img,args):\n",
    "    image_pil = PILImage.fromarray(cv_img)\n",
    "    width, height = image_pil.size\n",
    "    new_size = (int(width*args.scale),int(height*args.scale))\n",
    "    image_pil = image_pil.resize(new_size)\n",
    "    image = trans_to_tensor(image_pil)\n",
    "    return image\n",
    "\n",
    "CtRNet = CtRNet(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8578,  0.5140, -0.0044, -0.1976],\n",
      "         [ 0.0951, -0.1672, -0.9813,  0.3963],\n",
      "         [-0.5051,  0.8414, -0.1923,  1.0495],\n",
      "         [ 0.0000,  0.0000,  0.0000,  1.0000]]], device='cuda:0',\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "cv_img = cv2.imread(os.path.join(args.base_dir,\"images/panda.jpg\"))\n",
    "cv_img = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)\n",
    "image = preprocess_img(cv_img,args)\n",
    "if args.use_gpu:\n",
    "    image = image.cuda()\n",
    "\n",
    "joint_angles = np.array([ 0.0200, -0.9641, -0.0662, -2.7979, -0.0469,  1.9289,  0.9137])\n",
    "\n",
    "cTr, points_2d, segmentation, confidence = CtRNet.inference_single_image(image, joint_angles)\n",
    "print(CtRNet.cTr_to_pose_matrix(cTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.70867818e-04,  2.20735059e-04, -2.42856312e-04, -6.64493705e-05,\n",
       "       -3.56074489e-05,  9.41605532e-05])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_std = np.array([\n",
    "                        1.0e-2, 1.0e-2, 1.0e-2, # ori\n",
    "                        1.0e-3, 1.0e-3, 1.0e-3, # pos\n",
    "                    ])\n",
    "pred_std = np.array([1.0e-4, 1.0e-4, 1.0e-4,\n",
    "                     2.5e-5, 2.5e-5, 2.5e-5])\n",
    "pf = ParticleFilter(num_states=6,\n",
    "                    init_distribution=sample_gaussian,\n",
    "                    motion_model=additive_gaussian,\n",
    "                    obs_model=point_feature_obs,\n",
    "                    num_particles=200)\n",
    "pf.init_filter(init_std)\n",
    "\n",
    "pf.predict(pred_std)\n",
    "\n",
    "cam = None\n",
    "gamma = 0.15\n",
    "pf.update(points_2d, CtRNet, joint_angles, cam, cTr, gamma)\n",
    "pf.get_mean_particle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
